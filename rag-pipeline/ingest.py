#!/usr/bin/env python3
"""
Repository Ingestion Pipeline
Repo í´ë¡  í›„ ì½”ë“œ íŒŒì¼ ìˆ˜ì§‘ â†’ ì²­í‚¹ & ì„ë² ë”© â†’ VectorStore ì €ì¥
"""

import os
import sys
import git
import argparse
from pathlib import Path
from typing import List, Dict, Any
from dotenv import load_dotenv

import openai
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_openai.embeddings import OpenAIEmbeddings
import chromadb

load_dotenv()

# LangSmith ì¶”ì  í™œì„±í™”
os.environ["LANGCHAIN_TRACING_V2"] = "true"
if os.getenv("LANGCHAIN_API_KEY"):
    os.environ["LANGCHAIN_PROJECT"] = os.getenv("LANGCHAIN_PROJECT", "rag-system")

class RepositoryIngestor:
    def __init__(self):
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        if not self.openai_api_key:
            raise ValueError("OPENAI_API_KEY not found in environment variables")
        
        # OpenAI text-embedding-3-large ì‚¬ìš©
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-large",
            api_key=self.openai_api_key
        )
        
        # í…ìŠ¤íŠ¸ ìŠ¤í”Œë¦¬í„° ì„¤ì • (ì½”ë“œì— ìµœì í™”)
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            separators=["\n\n", "\n", " ", ""],
            length_function=len,
        )
        
        self.chroma_persist_dir = os.getenv("CHROMA_PERSIST_DIRECTORY", "./chroma_db")
    
    def clone_repository(self, repo_url: str, local_path: str = "./temp_repo") -> str:
        """GitHub ë ˆí¬ì§€í† ë¦¬ í´ë¡ """
        print(f"ğŸ“¥ Cloning repository: {repo_url}")
        
        # ê¸°ì¡´ ë””ë ‰í† ë¦¬ê°€ ìˆë‹¤ë©´ ì‚­ì œ
        if os.path.exists(local_path):
            import shutil
            shutil.rmtree(local_path)
        
        try:
            git.Repo.clone_from(repo_url, local_path)
            print(f"âœ… Repository cloned to: {local_path}")
            return local_path
        except Exception as e:
            print(f"âŒ Error cloning repository: {e}")
            raise
    
    def extract_code_files(self, repo_path: str) -> List[str]:
        """ì½”ë“œ íŒŒì¼ ì¶”ì¶œ (.kt, .java, .md ë“±)"""
        print(f"ğŸ” Extracting code files from: {repo_path}")
        
        # ì§€ì›í•˜ëŠ” íŒŒì¼ í™•ì¥ì
        code_extensions = {
            '.kt', '.java', '.py', '.js', '.ts', '.md', '.txt', 
            '.yml', '.yaml', '.json', '.xml', '.gradle', '.properties'
        }
        
        files = []
        ignored_dirs = {'.git', 'node_modules', '__pycache__', '.gradle', 'build', 'target'}
        
        for root, dirs, filenames in os.walk(repo_path):
            # ë¬´ì‹œí•  ë””ë ‰í† ë¦¬ ì œì™¸
            dirs[:] = [d for d in dirs if d not in ignored_dirs and not d.startswith('.')]
            
            for filename in filenames:
                file_path = os.path.join(root, filename)
                file_ext = Path(filename).suffix.lower()
                
                if file_ext in code_extensions:
                    files.append(file_path)
        
        print(f"âœ… Found {len(files)} code files")
        return files
    
    def process_files_to_chunks(self, file_paths: List[str]) -> List[Dict[str, Any]]:
        """íŒŒì¼ì„ ì²­í¬ë¡œ ë¶„í• í•˜ê³  ë©”íƒ€ë°ì´í„° ì¶”ê°€"""
        print(f"ğŸ“„ Processing {len(file_paths)} files into chunks...")
        
        documents = []
        
        for file_path in file_paths:
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                if not content.strip():
                    continue
                
                # íŒŒì¼ ë‚´ìš©ì„ ì²­í¬ë¡œ ë¶„í• 
                chunks = self.text_splitter.split_text(content)
                
                for i, chunk in enumerate(chunks):
                    documents.append({
                        'content': chunk,
                        'metadata': {
                            'source': file_path,
                            'chunk_index': i,
                            'total_chunks': len(chunks),
                            'file_type': Path(file_path).suffix,
                            'file_name': Path(file_path).name,
                            'relative_path': str(Path(file_path).relative_to(Path(file_path).parts[0]))
                        }
                    })
            
            except Exception as e:
                print(f"âš ï¸ Error processing {file_path}: {e}")
                continue
        
        print(f"âœ… Created {len(documents)} document chunks")
        return documents
    
    def create_vector_store(self, documents: List[Dict[str, Any]]) -> None:
        """ChromaDB ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ë° ì €ì¥"""
        print(f"ğŸ”„ Creating vector store with {len(documents)} chunks...")
        
        if not documents:
            print("âŒ No documents to process")
            return
        
        # í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„° ë¶„ë¦¬
        texts = [doc['content'] for doc in documents]
        metadatas = [doc['metadata'] for doc in documents]
        
        try:
            # ChromaDB ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
            vectorstore = Chroma.from_texts(
                texts=texts,
                metadatas=metadatas,
                embedding=self.embeddings,
                persist_directory=self.chroma_persist_dir
            )
            
            # ë²¡í„°ìŠ¤í† ì–´ ì €ì¥
            vectorstore.persist()
            print(f"âœ… Vector store created and saved to: {self.chroma_persist_dir}")
            
        except Exception as e:
            print(f"âŒ Error creating vector store: {e}")
            raise
    
    def ingest_repository(self, repo_url: str) -> None:
        """ì „ì²´ ingestion íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ğŸš€ Starting repository ingestion pipeline...")
        
        try:
            # 1. ë ˆí¬ì§€í† ë¦¬ í´ë¡ 
            repo_path = self.clone_repository(repo_url)
            
            # 2. ì½”ë“œ íŒŒì¼ ì¶”ì¶œ
            file_paths = self.extract_code_files(repo_path)
            
            # 3. íŒŒì¼ì„ ì²­í¬ë¡œ ë¶„í• 
            documents = self.process_files_to_chunks(file_paths)
            
            # 4. ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
            self.create_vector_store(documents)
            
            # 5. ì„ì‹œ íŒŒì¼ ì •ë¦¬
            import shutil
            shutil.rmtree(repo_path)
            print("ğŸ§¹ Cleaned up temporary files")
            
            print("ğŸ‰ Repository ingestion completed successfully!")
            
        except Exception as e:
            print(f"âŒ Ingestion failed: {e}")
            sys.exit(1)

def main():
    parser = argparse.ArgumentParser(description="Repository Ingestion Pipeline")
    parser.add_argument("--repo", required=True, help="Repository URL to ingest")
    parser.add_argument("--persist-dir", help="ChromaDB persist directory", 
                       default="./chroma_db")
    
    args = parser.parse_args()
    
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    if args.persist_dir:
        os.environ["CHROMA_PERSIST_DIRECTORY"] = args.persist_dir
    
    # Ingestion ì‹¤í–‰
    ingestor = RepositoryIngestor()
    ingestor.ingest_repository(args.repo)

if __name__ == "__main__":
    main()