#!/usr/bin/env python3
"""
Issue Query & Resolution Pipeline
Issue ë²ˆí˜¸ ì…ë ¥ â†’ VectorStore ê²€ìƒ‰ â†’ Tavily API ë¦¬ì„œì¹˜ â†’ OpenAI ChatCompletionìœ¼ë¡œ í•´ê²°ì±… ìƒì„±
"""

import os
import sys
import argparse
from typing import List, Dict, Any
from dotenv import load_dotenv

import openai
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from tavily import TavilyClient

load_dotenv()

class IssueQuerySystem:
    def __init__(self):
        # API í‚¤ í™•ì¸
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.tavily_api_key = os.getenv("TAVILY_API_KEY")
        
        if not self.openai_api_key:
            raise ValueError("OPENAI_API_KEY not found in environment variables")
        if not self.tavily_api_key:
            raise ValueError("TAVILY_API_KEY not found in environment variables")
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.openai_client = openai.OpenAI(api_key=self.openai_api_key)
        
        # Embeddings ì´ˆê¸°í™” (ingest.pyì™€ ë™ì¼í•œ ëª¨ë¸ ì‚¬ìš©)
        self.embeddings = OpenAIEmbeddings(
            model="text-embedding-3-large",
            api_key=self.openai_api_key
        )
        
        # Tavily í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.tavily_client = TavilyClient(api_key=self.tavily_api_key)
        
        # ChromaDB ì„¤ì •
        self.chroma_persist_dir = os.getenv("CHROMA_PERSIST_DIRECTORY", "./chroma_db")
        self.vectorstore = None
    
    def load_vector_store(self) -> None:
        """ì €ì¥ëœ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ"""
        print(f"ğŸ“š Loading vector store from: {self.chroma_persist_dir}")
        
        try:
            self.vectorstore = Chroma(
                persist_directory=self.chroma_persist_dir,
                embedding_function=self.embeddings
            )
            print("âœ… Vector store loaded successfully")
        except Exception as e:
            print(f"âŒ Error loading vector store: {e}")
            print("ğŸ’¡ Make sure you've run ingest.py first to create the vector store")
            raise
    
    def search_relevant_context(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """VectorStoreì—ì„œ ê´€ë ¨ëœ ì½”ë“œ ìŠ¤ë‹ˆí« ê²€ìƒ‰"""
        print(f"ğŸ” Searching for relevant context: '{query}'")
        
        if not self.vectorstore:
            self.load_vector_store()
        
        try:
            # ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰
            results = self.vectorstore.similarity_search_with_score(query, k=k)
            
            context_docs = []
            for doc, score in results:
                context_docs.append({
                    'content': doc.page_content,
                    'metadata': doc.metadata,
                    'similarity_score': float(score)
                })
            
            print(f"âœ… Found {len(context_docs)} relevant code snippets")
            return context_docs
            
        except Exception as e:
            print(f"âŒ Error during vector search: {e}")
            return []
    
    def tavily_research(self, query: str) -> str:
        """Tavily APIë¥¼ ì‚¬ìš©í•œ ì™¸ë¶€ ë¦¬ì„œì¹˜"""
        print(f"ğŸŒ Conducting external research: '{query}'")
        
        try:
            # Tavily ê²€ìƒ‰ ì‹¤í–‰
            response = self.tavily_client.search(
                query=query,
                search_depth="advanced",
                max_results=3,
                include_answer=True
            )
            
            research_content = ""
            
            # ë‹µë³€ì´ ìˆëŠ” ê²½ìš°
            if response.get('answer'):
                research_content += f"Research Summary: {response['answer']}\n\n"
            
            # ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
            for i, result in enumerate(response.get('results', []), 1):
                research_content += f"Result {i}:\n"
                research_content += f"Title: {result.get('title', 'N/A')}\n"
                research_content += f"Content: {result.get('content', 'N/A')}\n"
                research_content += f"URL: {result.get('url', 'N/A')}\n\n"
            
            print(f"âœ… External research completed ({len(response.get('results', []))} results)")
            return research_content
            
        except Exception as e:
            print(f"âš ï¸ External research failed: {e}")
            return "External research unavailable due to API error."
    
    def generate_solution(self, issue_description: str, context_docs: List[Dict], research_content: str) -> str:
        """OpenAI ChatCompletionìœ¼ë¡œ í•´ê²°ì±… ìƒì„±"""
        print("ğŸ¤– Generating solution using OpenAI GPT-4...")
        
        # ì½”ë“œ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        code_context = ""
        for i, doc in enumerate(context_docs, 1):
            code_context += f"Code Snippet {i}:\n"
            code_context += f"File: {doc['metadata'].get('source', 'Unknown')}\n"
            code_context += f"File Type: {doc['metadata'].get('file_type', 'Unknown')}\n"
            code_context += f"Similarity Score: {doc['similarity_score']:.3f}\n"
            code_context += f"Content:\n{doc['content']}\n"
            code_context += "-" * 50 + "\n"
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = """ë‹¹ì‹ ì€ Spring Bootì™€ Kotlinì— ì „ë¬¸ì„±ì„ ê°€ì§„ ì‹œë‹ˆì–´ ê°œë°œìì…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ ì´ìŠˆì— ëŒ€í•´ ì½”ë“œ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ì‹¤ìš©ì ì¸ í•´ê²°ì±…ì„ ì œì‹œí•´ì£¼ì„¸ìš”.

ì‘ë‹µ í˜•ì‹:
1. ë¬¸ì œ ë¶„ì„
2. ì›ì¸ íŒŒì•…  
3. í•´ê²° ë°©ì•ˆ
4. ì½”ë“œ ì˜ˆì‹œ (í•„ìš”í•œ ê²½ìš°)
5. ì¶”ê°€ ê¶Œì¥ì‚¬í•­

í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

        user_prompt = f"""
ì´ìŠˆ ì„¤ëª…:
{issue_description}

ê´€ë ¨ ì½”ë“œ ì»¨í…ìŠ¤íŠ¸:
{code_context}

ì™¸ë¶€ ë¦¬ì„œì¹˜ ê²°ê³¼:
{research_content}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ìŠˆì— ëŒ€í•œ ì¢…í•©ì ì¸ í•´ê²°ì±…ì„ ì œì‹œí•´ì£¼ì„¸ìš”.
"""

        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=2000,
                temperature=0.7
            )
            
            solution = response.choices[0].message.content
            print("âœ… Solution generated successfully")
            return solution
            
        except Exception as e:
            print(f"âŒ Error generating solution: {e}")
            return f"í•´ê²°ì±… ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
    
    def resolve_issue(self, issue_description: str) -> Dict[str, Any]:
        """ì „ì²´ ì´ìŠˆ í•´ê²° íŒŒì´í”„ë¼ì¸"""
        print(f"ğŸ¯ Starting issue resolution for: {issue_description}")
        
        # 1. ê´€ë ¨ ì½”ë“œ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
        context_docs = self.search_relevant_context(issue_description)
        
        # 2. ì™¸ë¶€ ë¦¬ì„œì¹˜ ìˆ˜í–‰
        research_query = f"spring boot kotlin {issue_description} solution"
        research_content = self.tavily_research(research_query)
        
        # 3. í•´ê²°ì±… ìƒì„±
        solution = self.generate_solution(issue_description, context_docs, research_content)
        
        # ê²°ê³¼ ì •ë¦¬
        result = {
            'issue': issue_description,
            'relevant_files': [doc['metadata'].get('source', 'Unknown') for doc in context_docs],
            'context_docs': context_docs,
            'research_content': research_content,
            'solution': solution
        }
        
        print("ğŸ‰ Issue resolution completed!")
        return result
    
    def print_resolution_report(self, result: Dict[str, Any]) -> None:
        """í•´ê²°ì±… ë¦¬í¬íŠ¸ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸ“‹ ISSUE RESOLUTION REPORT")
        print("="*80)
        
        print(f"\nğŸ¯ Issue: {result['issue']}")
        
        print(f"\nğŸ“ Relevant Files ({len(result['relevant_files'])}):")
        for file in result['relevant_files'][:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ
            print(f"  â€¢ {file}")
        
        print(f"\nğŸ¤– Solution:")
        print("-" * 40)
        print(result['solution'])
        
        if result['research_content'] and "External research unavailable" not in result['research_content']:
            print(f"\nğŸŒ External Research:")
            print("-" * 40)
            research_lines = result['research_content'].split('\n')[:10]  # ì²˜ìŒ 10ì¤„ë§Œ
            print('\n'.join(research_lines))
            if len(result['research_content'].split('\n')) > 10:
                print("... (more research results available)")
        
        print("\n" + "="*80)

def main():
    parser = argparse.ArgumentParser(description="Issue Query & Resolution System")
    parser.add_argument("--issue", required=True, help="Issue description or issue number")
    parser.add_argument("--persist-dir", help="ChromaDB persist directory", 
                       default="./chroma_db")
    
    args = parser.parse_args()
    
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    if args.persist_dir:
        os.environ["CHROMA_PERSIST_DIRECTORY"] = args.persist_dir
    
    try:
        # ì¿¼ë¦¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        query_system = IssueQuerySystem()
        
        # ì´ìŠˆ í•´ê²°
        result = query_system.resolve_issue(args.issue)
        
        # ê²°ê³¼ ì¶œë ¥
        query_system.print_resolution_report(result)
        
    except Exception as e:
        print(f"âŒ Query system failed: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()